model:
  key: GeneratorV3SelfAttention
  params:
    channel: 256
    k: 4096
    size: [16, 8, 8, 8, 8, 4, 4, 4, 4, 2, 2, 2, 2, 1, 1, 1, 1]
    denseNorm: false
    qk_norm: true
    norm_eps: 1.e-5
    loadFrom: compressor/val_40000.ckpt
train:
  totalStep: 25000 # totalimage / gpus / batchsize * epochs (6354785 / 8 / 6 * 1.5)
  batchSize: 48
  epoch: 2
  valFreq: 2500
  trainSet: /ssdfs/datahome/tj24011/datasets/raw/imagenet/imagenet-1k
  valSet: /ssdfs/datahome/tj24011/datasets/raw/kodak
  saveDir: /ssdfs/datahome/tj24011/workspace/McQuic/generation_saved
  target: MsSSIM
  externalLib: []
    # - some/modules/to/be/registered1.py
    # - some/modules/to/be/registered2.py
  optim:
    key: FusedLAMB
    params:
      lr: 1.e-4 # PSNR: 5.e-3 # don't try to tune lr, it is best
      weight_decay: 0.0
      # use_nvlamb: true
  schdr:
    # key: Placeholder
    key: CosineAnnealingWarmupRestarts
    params:
      first_cycle_steps: 25000 # totalimage / gpus / batchsize * epochs
      warmup_steps: 750
      gamma: 1.0
      lrScaleRatio: 0.0
  gpu:
    gpus: 8
    vRam: -1
    wantsMore: false
